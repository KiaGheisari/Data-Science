{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "DYEnyJtyUK_P"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import callbacks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Air.csv')"
      ],
      "metadata": {
        "id": "higSz9alY6Ne"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df.pop('PT08.S5(O3)')\n",
        "y2 = y > 1500"
      ],
      "metadata": {
        "id": "_y6zsNZlbdM9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "transformed_data = scaler.fit_transform(df)"
      ],
      "metadata": {
        "id": "sIgX6OU7bkh_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(transformed_data,y,test_size=0.2)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C32ir0nbm_7",
        "outputId": "124d7793-7fdc-499d-ab8f-7c3c53aaffbe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7485, 17)\n",
            "(1872, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_binary, X_test_binary, y_train_binary, y_test_binary = train_test_split(transformed_data,y2,test_size=0.2)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WGesrsJbst3",
        "outputId": "9a5e9b07-4b0d-4dac-c80b-7b48ac64222c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7485, 17)\n",
            "(1872, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Layer FF Neural netwrok with Keras"
      ],
      "metadata": {
        "id": "bfJeXE9xElKS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binary Classification"
      ],
      "metadata": {
        "id": "IT0NZVCUEDZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "early_stopping = callbacks.EarlyStopping(\n",
        "    min_delta=0.001,\n",
        "    patience=20,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2 , callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tUfYJoYDb4tF",
        "outputId": "5a715297-f746-478b-afb5-270576b40268"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1010208.3750 - mae: 897.4184 - val_loss: 77739.4766 - val_mae: 226.7750\n",
            "Epoch 2/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 70468.6328 - mae: 214.3525 - val_loss: 39147.0781 - val_mae: 156.7537\n",
            "Epoch 3/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 34112.9375 - mae: 145.8615 - val_loss: 25718.7383 - val_mae: 123.9197\n",
            "Epoch 4/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 26485.0039 - mae: 124.9528 - val_loss: 23754.7852 - val_mae: 117.7932\n",
            "Epoch 5/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 24561.0410 - mae: 119.8789 - val_loss: 22481.2461 - val_mae: 115.5355\n",
            "Epoch 6/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 20526.2578 - mae: 110.2900 - val_loss: 21849.2988 - val_mae: 114.9749\n",
            "Epoch 7/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 22456.7051 - mae: 113.6710 - val_loss: 21574.8359 - val_mae: 115.0563\n",
            "Epoch 8/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 20422.8945 - mae: 109.6337 - val_loss: 20616.0098 - val_mae: 111.6673\n",
            "Epoch 9/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 18930.6621 - mae: 105.2312 - val_loss: 19832.5527 - val_mae: 108.3029\n",
            "Epoch 10/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 19121.2188 - mae: 105.5688 - val_loss: 19289.1172 - val_mae: 106.9054\n",
            "Epoch 11/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 18499.3574 - mae: 104.0157 - val_loss: 18903.0918 - val_mae: 105.6422\n",
            "Epoch 12/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 18294.9121 - mae: 101.9452 - val_loss: 18537.3027 - val_mae: 104.4911\n",
            "Epoch 13/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 18729.5137 - mae: 104.2071 - val_loss: 18153.8145 - val_mae: 104.0347\n",
            "Epoch 14/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 18489.4980 - mae: 102.4801 - val_loss: 17813.2812 - val_mae: 103.5340\n",
            "Epoch 15/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 18900.3438 - mae: 103.1768 - val_loss: 17924.9375 - val_mae: 102.3056\n",
            "Epoch 16/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16896.8730 - mae: 99.1933 - val_loss: 17848.7598 - val_mae: 104.9638\n",
            "Epoch 17/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 17129.6406 - mae: 100.1664 - val_loss: 17228.3633 - val_mae: 101.8462\n",
            "Epoch 18/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16640.6445 - mae: 98.5828 - val_loss: 17391.0156 - val_mae: 100.4570\n",
            "Epoch 19/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16988.0547 - mae: 99.1734 - val_loss: 16886.2949 - val_mae: 99.9328\n",
            "Epoch 20/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16151.7979 - mae: 97.0661 - val_loss: 16719.7754 - val_mae: 100.3183\n",
            "Epoch 21/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16707.1445 - mae: 99.3798 - val_loss: 16940.2363 - val_mae: 102.1724\n",
            "Epoch 22/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16446.9590 - mae: 98.8320 - val_loss: 16576.0879 - val_mae: 100.5470\n",
            "Epoch 23/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 16169.3340 - mae: 97.2486 - val_loss: 16778.3203 - val_mae: 98.6824\n",
            "Epoch 24/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 15779.0625 - mae: 96.7922 - val_loss: 16657.2598 - val_mae: 98.4246\n",
            "Epoch 25/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16091.9346 - mae: 97.5494 - val_loss: 16151.3584 - val_mae: 99.7792\n",
            "Epoch 26/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15947.7217 - mae: 97.0975 - val_loss: 15812.3955 - val_mae: 98.2413\n",
            "Epoch 27/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15356.1719 - mae: 94.4868 - val_loss: 15906.1885 - val_mae: 96.8322\n",
            "Epoch 28/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15419.7373 - mae: 94.7467 - val_loss: 15682.0117 - val_mae: 96.1065\n",
            "Epoch 29/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 14520.8975 - mae: 92.7445 - val_loss: 15834.3564 - val_mae: 99.2054\n",
            "Epoch 30/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15585.5303 - mae: 95.8025 - val_loss: 15204.8789 - val_mae: 95.7458\n",
            "Epoch 31/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15044.7920 - mae: 95.1689 - val_loss: 15045.2275 - val_mae: 95.5445\n",
            "Epoch 32/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 14555.1426 - mae: 92.9641 - val_loss: 14934.1768 - val_mae: 94.7563\n",
            "Epoch 33/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 14839.7021 - mae: 93.0968 - val_loss: 14876.3623 - val_mae: 94.2757\n",
            "Epoch 34/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 14138.9121 - mae: 91.7230 - val_loss: 14575.5742 - val_mae: 93.9922\n",
            "Epoch 35/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 14411.1914 - mae: 91.7308 - val_loss: 14657.0684 - val_mae: 94.9430\n",
            "Epoch 36/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 14696.9570 - mae: 92.0956 - val_loss: 14403.7461 - val_mae: 92.6363\n",
            "Epoch 37/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 13824.6738 - mae: 89.6234 - val_loss: 14250.1787 - val_mae: 92.4496\n",
            "Epoch 38/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13884.2295 - mae: 90.1530 - val_loss: 14053.1367 - val_mae: 91.6332\n",
            "Epoch 39/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13212.7656 - mae: 88.4854 - val_loss: 14073.5898 - val_mae: 92.7427\n",
            "Epoch 40/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13564.5908 - mae: 89.2014 - val_loss: 13993.3750 - val_mae: 91.2739\n",
            "Epoch 41/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 14317.7285 - mae: 91.2359 - val_loss: 14202.0469 - val_mae: 90.9692\n",
            "Epoch 42/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13171.9062 - mae: 87.8543 - val_loss: 13576.2432 - val_mae: 90.1940\n",
            "Epoch 43/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13160.1299 - mae: 88.2185 - val_loss: 13477.6514 - val_mae: 90.2474\n",
            "Epoch 44/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12826.1914 - mae: 86.6562 - val_loss: 15185.0918 - val_mae: 98.3198\n",
            "Epoch 45/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13782.1816 - mae: 88.7993 - val_loss: 13538.2832 - val_mae: 88.8136\n",
            "Epoch 46/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13093.4932 - mae: 87.1419 - val_loss: 13553.1133 - val_mae: 91.0436\n",
            "Epoch 47/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 13517.9033 - mae: 88.4245 - val_loss: 13070.5254 - val_mae: 88.1220\n",
            "Epoch 48/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 12670.6758 - mae: 86.2710 - val_loss: 13172.2080 - val_mae: 88.1095\n",
            "Epoch 49/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13486.5361 - mae: 88.5767 - val_loss: 13482.9629 - val_mae: 88.6421\n",
            "Epoch 50/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13003.0693 - mae: 87.2788 - val_loss: 12960.4971 - val_mae: 87.6266\n",
            "Epoch 51/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12630.3047 - mae: 86.6984 - val_loss: 12846.3643 - val_mae: 87.5848\n",
            "Epoch 52/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13039.6826 - mae: 87.3335 - val_loss: 13174.2100 - val_mae: 87.7807\n",
            "Epoch 53/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13042.7393 - mae: 86.8485 - val_loss: 12639.6982 - val_mae: 86.9322\n",
            "Epoch 54/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 13330.9658 - mae: 88.8442 - val_loss: 12751.2256 - val_mae: 87.2840\n",
            "Epoch 55/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12140.8359 - mae: 83.5831 - val_loss: 12813.6670 - val_mae: 88.3689\n",
            "Epoch 56/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12226.3936 - mae: 84.4457 - val_loss: 12971.9336 - val_mae: 89.2771\n",
            "Epoch 57/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11918.2129 - mae: 84.0219 - val_loss: 12546.3115 - val_mae: 87.1468\n",
            "Epoch 58/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12522.5332 - mae: 84.8783 - val_loss: 12489.0674 - val_mae: 86.5826\n",
            "Epoch 59/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12756.7256 - mae: 85.4705 - val_loss: 12433.1328 - val_mae: 85.6822\n",
            "Epoch 60/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 13218.1543 - mae: 86.4805 - val_loss: 12615.1025 - val_mae: 85.9051\n",
            "Epoch 61/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12428.9785 - mae: 84.9106 - val_loss: 12663.7217 - val_mae: 86.3922\n",
            "Epoch 62/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12610.4404 - mae: 85.5261 - val_loss: 12460.0479 - val_mae: 85.7365\n",
            "Epoch 63/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12922.8154 - mae: 86.8710 - val_loss: 12475.1514 - val_mae: 87.2181\n",
            "Epoch 64/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12297.8135 - mae: 85.4919 - val_loss: 12558.9111 - val_mae: 85.4909\n",
            "Epoch 65/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11764.9502 - mae: 82.8273 - val_loss: 12219.5889 - val_mae: 85.8813\n",
            "Epoch 66/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12353.7246 - mae: 84.3498 - val_loss: 12291.3906 - val_mae: 86.3659\n",
            "Epoch 67/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12478.0635 - mae: 83.9566 - val_loss: 12758.5996 - val_mae: 86.6344\n",
            "Epoch 68/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12096.6699 - mae: 84.5028 - val_loss: 13905.2559 - val_mae: 89.9996\n",
            "Epoch 69/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11585.2646 - mae: 82.6925 - val_loss: 13858.6182 - val_mae: 89.4208\n",
            "Epoch 70/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11552.5195 - mae: 83.0385 - val_loss: 11951.0752 - val_mae: 84.6448\n",
            "Epoch 71/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11841.3027 - mae: 83.7174 - val_loss: 12189.3584 - val_mae: 84.8022\n",
            "Epoch 72/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12280.1445 - mae: 83.7944 - val_loss: 11893.4336 - val_mae: 84.4644\n",
            "Epoch 73/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11735.0439 - mae: 82.7202 - val_loss: 12211.6055 - val_mae: 86.7073\n",
            "Epoch 74/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 11999.6064 - mae: 83.0465 - val_loss: 12070.0107 - val_mae: 86.0140\n",
            "Epoch 75/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11810.8779 - mae: 82.9277 - val_loss: 12317.7158 - val_mae: 87.3607\n",
            "Epoch 76/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11771.9463 - mae: 82.9271 - val_loss: 12090.3447 - val_mae: 84.7159\n",
            "Epoch 77/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11257.1172 - mae: 80.6008 - val_loss: 13022.1465 - val_mae: 90.8528\n",
            "Epoch 78/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11454.9434 - mae: 82.0471 - val_loss: 11615.1904 - val_mae: 83.4289\n",
            "Epoch 79/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11343.1582 - mae: 81.6199 - val_loss: 11645.0020 - val_mae: 83.4633\n",
            "Epoch 80/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11126.8555 - mae: 80.5337 - val_loss: 11584.3457 - val_mae: 82.8591\n",
            "Epoch 81/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11440.6543 - mae: 81.5530 - val_loss: 11534.7646 - val_mae: 82.7299\n",
            "Epoch 82/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 10989.2266 - mae: 80.3800 - val_loss: 11533.8613 - val_mae: 83.8627\n",
            "Epoch 83/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 10508.5977 - mae: 79.1835 - val_loss: 12688.5127 - val_mae: 89.8917\n",
            "Epoch 84/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11955.6016 - mae: 84.1793 - val_loss: 11753.4785 - val_mae: 84.9929\n",
            "Epoch 85/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11232.3477 - mae: 80.3640 - val_loss: 11302.4053 - val_mae: 82.4533\n",
            "Epoch 86/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 10707.0205 - mae: 79.0115 - val_loss: 11776.3271 - val_mae: 82.8664\n",
            "Epoch 87/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12390.6016 - mae: 82.2608 - val_loss: 11238.1387 - val_mae: 82.3887\n",
            "Epoch 88/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 10966.7412 - mae: 80.3187 - val_loss: 11299.0195 - val_mae: 82.8432\n",
            "Epoch 89/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11101.3984 - mae: 79.1942 - val_loss: 11346.1113 - val_mae: 83.2530\n",
            "Epoch 90/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 10980.0312 - mae: 80.4462 - val_loss: 11127.7490 - val_mae: 82.1057\n",
            "Epoch 91/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11130.3838 - mae: 80.2185 - val_loss: 11380.9795 - val_mae: 81.9605\n",
            "Epoch 92/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 10916.8848 - mae: 79.2161 - val_loss: 11336.2207 - val_mae: 81.6751\n",
            "Epoch 93/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 10941.6367 - mae: 79.4965 - val_loss: 11240.3965 - val_mae: 82.0758\n",
            "Epoch 94/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 10927.3115 - mae: 79.8390 - val_loss: 11011.3633 - val_mae: 81.2952\n",
            "Epoch 95/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11455.2637 - mae: 80.8557 - val_loss: 11162.1680 - val_mae: 81.0119\n",
            "Epoch 96/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11290.1211 - mae: 80.6522 - val_loss: 11430.4199 - val_mae: 83.7154\n",
            "Epoch 97/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 10900.4043 - mae: 79.0862 - val_loss: 11115.2305 - val_mae: 81.1493\n",
            "Epoch 98/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 10925.4717 - mae: 78.8102 - val_loss: 10944.1953 - val_mae: 80.9627\n",
            "Epoch 99/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 10699.3857 - mae: 78.9012 - val_loss: 10918.9795 - val_mae: 80.3639\n",
            "Epoch 100/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 10441.7773 - mae: 77.5010 - val_loss: 13449.2061 - val_mae: 88.2011\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f550c9a2c50>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "print(r2_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYz2oDRMd6r2",
        "outputId": "81facf46-818a-47a4-ad53-cf561067455d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "0.9240962951911724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression"
      ],
      "metadata": {
        "id": "-LExli4nET4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1 , activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "early_stopping = callbacks.EarlyStopping(\n",
        "    min_delta=0.001,\n",
        "    patience=20,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=[tf.keras.metrics.Precision(),tf.keras.metrics.Recall()],\n",
        "    )\n",
        "\n",
        "model.fit(X_train_binary, y_train_binary, epochs=150, batch_size=32, validation_split=0.2 , callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oMgfoSaAg5fR",
        "outputId": "0158b25c-60fa-43d4-85f0-740bb9821adb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.3964 - precision_2: 0.5594 - recall_2: 0.0674 - val_loss: 0.1522 - val_precision_2: 0.7675 - val_recall_2: 0.8216\n",
            "Epoch 2/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1386 - precision_2: 0.8209 - recall_2: 0.7842 - val_loss: 0.1321 - val_precision_2: 0.8103 - val_recall_2: 0.7418\n",
            "Epoch 3/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1257 - precision_2: 0.8261 - recall_2: 0.7711 - val_loss: 0.1574 - val_precision_2: 0.9624 - val_recall_2: 0.6009\n",
            "Epoch 4/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1279 - precision_2: 0.8308 - recall_2: 0.7813 - val_loss: 0.1314 - val_precision_2: 0.8736 - val_recall_2: 0.7136\n",
            "Epoch 5/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1093 - precision_2: 0.8453 - recall_2: 0.8006 - val_loss: 0.1224 - val_precision_2: 0.7883 - val_recall_2: 0.8216\n",
            "Epoch 6/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1084 - precision_2: 0.8567 - recall_2: 0.8021 - val_loss: 0.1292 - val_precision_2: 0.8837 - val_recall_2: 0.7136\n",
            "Epoch 7/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1078 - precision_2: 0.8484 - recall_2: 0.7998 - val_loss: 0.1384 - val_precision_2: 0.7276 - val_recall_2: 0.8779\n",
            "Epoch 8/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1136 - precision_2: 0.8478 - recall_2: 0.8106 - val_loss: 0.1214 - val_precision_2: 0.9086 - val_recall_2: 0.7465\n",
            "Epoch 9/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1035 - precision_2: 0.8584 - recall_2: 0.7732 - val_loss: 0.1321 - val_precision_2: 0.7480 - val_recall_2: 0.8779\n",
            "Epoch 10/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1131 - precision_2: 0.8255 - recall_2: 0.7958 - val_loss: 0.1316 - val_precision_2: 0.9351 - val_recall_2: 0.6761\n",
            "Epoch 11/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1061 - precision_2: 0.8726 - recall_2: 0.8290 - val_loss: 0.1141 - val_precision_2: 0.8153 - val_recall_2: 0.8498\n",
            "Epoch 12/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1045 - precision_2: 0.8338 - recall_2: 0.8105 - val_loss: 0.1140 - val_precision_2: 0.8034 - val_recall_2: 0.8826\n",
            "Epoch 13/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1109 - precision_2: 0.8348 - recall_2: 0.8038 - val_loss: 0.1161 - val_precision_2: 0.8079 - val_recall_2: 0.8685\n",
            "Epoch 14/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0927 - precision_2: 0.8672 - recall_2: 0.8248 - val_loss: 0.1108 - val_precision_2: 0.8465 - val_recall_2: 0.8545\n",
            "Epoch 15/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1053 - precision_2: 0.8619 - recall_2: 0.8163 - val_loss: 0.1123 - val_precision_2: 0.8537 - val_recall_2: 0.8216\n",
            "Epoch 16/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1062 - precision_2: 0.8576 - recall_2: 0.8244 - val_loss: 0.1091 - val_precision_2: 0.8426 - val_recall_2: 0.8545\n",
            "Epoch 17/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1016 - precision_2: 0.8622 - recall_2: 0.8095 - val_loss: 0.1074 - val_precision_2: 0.8433 - val_recall_2: 0.8592\n",
            "Epoch 18/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0987 - precision_2: 0.8548 - recall_2: 0.8405 - val_loss: 0.1071 - val_precision_2: 0.8519 - val_recall_2: 0.8638\n",
            "Epoch 19/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0983 - precision_2: 0.8569 - recall_2: 0.8312 - val_loss: 0.1079 - val_precision_2: 0.8451 - val_recall_2: 0.8451\n",
            "Epoch 20/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1049 - precision_2: 0.8461 - recall_2: 0.8218 - val_loss: 0.1103 - val_precision_2: 0.8295 - val_recall_2: 0.8451\n",
            "Epoch 21/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1013 - precision_2: 0.8496 - recall_2: 0.8397 - val_loss: 0.1094 - val_precision_2: 0.8483 - val_recall_2: 0.8404\n",
            "Epoch 22/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0953 - precision_2: 0.8786 - recall_2: 0.8116 - val_loss: 0.1093 - val_precision_2: 0.8848 - val_recall_2: 0.7934\n",
            "Epoch 23/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0973 - precision_2: 0.8697 - recall_2: 0.8294 - val_loss: 0.1104 - val_precision_2: 0.8273 - val_recall_2: 0.8545\n",
            "Epoch 24/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0997 - precision_2: 0.8437 - recall_2: 0.8242 - val_loss: 0.1257 - val_precision_2: 0.7638 - val_recall_2: 0.9108\n",
            "Epoch 25/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0979 - precision_2: 0.8421 - recall_2: 0.8088 - val_loss: 0.1181 - val_precision_2: 0.9148 - val_recall_2: 0.7559\n",
            "Epoch 26/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0948 - precision_2: 0.8765 - recall_2: 0.8263 - val_loss: 0.1197 - val_precision_2: 0.7831 - val_recall_2: 0.9155\n",
            "Epoch 27/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0940 - precision_2: 0.8650 - recall_2: 0.8553 - val_loss: 0.1175 - val_precision_2: 0.7823 - val_recall_2: 0.9108\n",
            "Epoch 28/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1009 - precision_2: 0.8544 - recall_2: 0.8375 - val_loss: 0.1122 - val_precision_2: 0.7854 - val_recall_2: 0.9108\n",
            "Epoch 29/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1006 - precision_2: 0.8699 - recall_2: 0.8388 - val_loss: 0.1078 - val_precision_2: 0.8222 - val_recall_2: 0.8685\n",
            "Epoch 30/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0949 - precision_2: 0.8977 - recall_2: 0.8401 - val_loss: 0.1057 - val_precision_2: 0.8808 - val_recall_2: 0.7981\n",
            "Epoch 31/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0981 - precision_2: 0.8885 - recall_2: 0.8224 - val_loss: 0.1078 - val_precision_2: 0.8641 - val_recall_2: 0.8357\n",
            "Epoch 32/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0903 - precision_2: 0.8788 - recall_2: 0.8307 - val_loss: 0.1054 - val_precision_2: 0.8696 - val_recall_2: 0.8451\n",
            "Epoch 33/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0878 - precision_2: 0.8866 - recall_2: 0.8651 - val_loss: 0.1498 - val_precision_2: 0.6899 - val_recall_2: 0.9296\n",
            "Epoch 34/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1036 - precision_2: 0.8525 - recall_2: 0.8510 - val_loss: 0.1093 - val_precision_2: 0.8416 - val_recall_2: 0.8732\n",
            "Epoch 35/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0883 - precision_2: 0.8810 - recall_2: 0.8407 - val_loss: 0.1085 - val_precision_2: 0.8984 - val_recall_2: 0.7887\n",
            "Epoch 36/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0999 - precision_2: 0.8727 - recall_2: 0.8076 - val_loss: 0.1050 - val_precision_2: 0.8384 - val_recall_2: 0.9014\n",
            "Epoch 37/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0839 - precision_2: 0.8879 - recall_2: 0.8522 - val_loss: 0.1098 - val_precision_2: 0.8913 - val_recall_2: 0.7700\n",
            "Epoch 38/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0925 - precision_2: 0.8779 - recall_2: 0.8304 - val_loss: 0.1036 - val_precision_2: 0.8719 - val_recall_2: 0.8310\n",
            "Epoch 39/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0855 - precision_2: 0.8921 - recall_2: 0.8521 - val_loss: 0.1222 - val_precision_2: 0.7539 - val_recall_2: 0.9061\n",
            "Epoch 40/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0952 - precision_2: 0.8709 - recall_2: 0.8557 - val_loss: 0.1054 - val_precision_2: 0.8378 - val_recall_2: 0.8732\n",
            "Epoch 41/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0957 - precision_2: 0.8716 - recall_2: 0.8212 - val_loss: 0.1090 - val_precision_2: 0.8220 - val_recall_2: 0.9108\n",
            "Epoch 42/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0913 - precision_2: 0.8760 - recall_2: 0.8430 - val_loss: 0.1238 - val_precision_2: 0.7510 - val_recall_2: 0.9202\n",
            "Epoch 43/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0936 - precision_2: 0.8731 - recall_2: 0.8435 - val_loss: 0.1138 - val_precision_2: 0.7934 - val_recall_2: 0.9014\n",
            "Epoch 44/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0870 - precision_2: 0.8793 - recall_2: 0.8530 - val_loss: 0.1060 - val_precision_2: 0.8253 - val_recall_2: 0.8873\n",
            "Epoch 45/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0886 - precision_2: 0.8709 - recall_2: 0.8520 - val_loss: 0.1000 - val_precision_2: 0.8571 - val_recall_2: 0.8732\n",
            "Epoch 46/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0870 - precision_2: 0.8712 - recall_2: 0.8693 - val_loss: 0.1005 - val_precision_2: 0.8632 - val_recall_2: 0.8592\n",
            "Epoch 47/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0895 - precision_2: 0.8761 - recall_2: 0.8398 - val_loss: 0.1094 - val_precision_2: 0.8000 - val_recall_2: 0.9014\n",
            "Epoch 48/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0819 - precision_2: 0.8819 - recall_2: 0.8624 - val_loss: 0.1116 - val_precision_2: 0.8017 - val_recall_2: 0.9108\n",
            "Epoch 49/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0846 - precision_2: 0.8623 - recall_2: 0.8640 - val_loss: 0.1084 - val_precision_2: 0.8050 - val_recall_2: 0.9108\n",
            "Epoch 50/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0808 - precision_2: 0.8752 - recall_2: 0.8466 - val_loss: 0.1296 - val_precision_2: 0.7228 - val_recall_2: 0.9061\n",
            "Epoch 51/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0902 - precision_2: 0.8620 - recall_2: 0.8738 - val_loss: 0.1011 - val_precision_2: 0.8539 - val_recall_2: 0.8779\n",
            "Epoch 52/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0769 - precision_2: 0.9111 - recall_2: 0.8719 - val_loss: 0.1075 - val_precision_2: 0.8512 - val_recall_2: 0.8592\n",
            "Epoch 53/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0729 - precision_2: 0.8872 - recall_2: 0.8841 - val_loss: 0.0985 - val_precision_2: 0.8780 - val_recall_2: 0.8451\n",
            "Epoch 54/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0840 - precision_2: 0.8714 - recall_2: 0.8514 - val_loss: 0.0989 - val_precision_2: 0.8829 - val_recall_2: 0.8498\n",
            "Epoch 55/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0770 - precision_2: 0.9064 - recall_2: 0.8553 - val_loss: 0.0984 - val_precision_2: 0.8744 - val_recall_2: 0.8498\n",
            "Epoch 56/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0791 - precision_2: 0.9052 - recall_2: 0.8571 - val_loss: 0.0983 - val_precision_2: 0.8645 - val_recall_2: 0.8685\n",
            "Epoch 57/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0877 - precision_2: 0.8907 - recall_2: 0.8562 - val_loss: 0.1032 - val_precision_2: 0.8824 - val_recall_2: 0.8451\n",
            "Epoch 58/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0757 - precision_2: 0.8844 - recall_2: 0.8797 - val_loss: 0.1028 - val_precision_2: 0.8955 - val_recall_2: 0.8451\n",
            "Epoch 59/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0928 - precision_2: 0.8551 - recall_2: 0.8661 - val_loss: 0.0998 - val_precision_2: 0.8551 - val_recall_2: 0.8592\n",
            "Epoch 60/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0862 - precision_2: 0.9016 - recall_2: 0.8689 - val_loss: 0.1178 - val_precision_2: 0.7647 - val_recall_2: 0.9155\n",
            "Epoch 61/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0796 - precision_2: 0.8948 - recall_2: 0.8767 - val_loss: 0.1030 - val_precision_2: 0.8139 - val_recall_2: 0.8826\n",
            "Epoch 62/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0864 - precision_2: 0.8806 - recall_2: 0.8515 - val_loss: 0.1031 - val_precision_2: 0.8565 - val_recall_2: 0.8685\n",
            "Epoch 63/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0838 - precision_2: 0.8840 - recall_2: 0.8537 - val_loss: 0.1066 - val_precision_2: 0.8447 - val_recall_2: 0.8685\n",
            "Epoch 64/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0820 - precision_2: 0.8742 - recall_2: 0.8534 - val_loss: 0.1416 - val_precision_2: 0.9245 - val_recall_2: 0.6901\n",
            "Epoch 65/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0879 - precision_2: 0.8938 - recall_2: 0.8443 - val_loss: 0.1042 - val_precision_2: 0.8818 - val_recall_2: 0.8404\n",
            "Epoch 66/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0842 - precision_2: 0.8823 - recall_2: 0.8599 - val_loss: 0.1070 - val_precision_2: 0.8122 - val_recall_2: 0.8732\n",
            "Epoch 67/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0803 - precision_2: 0.8965 - recall_2: 0.8692 - val_loss: 0.1062 - val_precision_2: 0.8447 - val_recall_2: 0.8685\n",
            "Epoch 68/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0839 - precision_2: 0.8768 - recall_2: 0.8705 - val_loss: 0.1020 - val_precision_2: 0.8708 - val_recall_2: 0.8545\n",
            "Epoch 69/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0728 - precision_2: 0.8854 - recall_2: 0.8745 - val_loss: 0.1049 - val_precision_2: 0.8155 - val_recall_2: 0.8920\n",
            "Epoch 70/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0795 - precision_2: 0.9011 - recall_2: 0.8570 - val_loss: 0.1140 - val_precision_2: 0.7769 - val_recall_2: 0.9155\n",
            "Epoch 71/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0747 - precision_2: 0.8911 - recall_2: 0.8776 - val_loss: 0.0976 - val_precision_2: 0.8826 - val_recall_2: 0.8826\n",
            "Epoch 72/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0855 - precision_2: 0.8834 - recall_2: 0.8621 - val_loss: 0.1047 - val_precision_2: 0.8261 - val_recall_2: 0.8920\n",
            "Epoch 73/150\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0746 - precision_2: 0.9033 - recall_2: 0.8761 - val_loss: 0.1019 - val_precision_2: 0.8210 - val_recall_2: 0.8826\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f550c217f50>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "predictions = model.predict(X_test_binary)\n",
        "print(f1_score(y_test_binary, predictions.round()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuWMP5jTijhm",
        "outputId": "5749199e-4fd9-4fa1-ba76-b3900c5afb99"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "0.8553971486761711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4-layer non-sequential feedforward network with Keras"
      ],
      "metadata": {
        "id": "YNuy1nucErPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binary Classification"
      ],
      "metadata": {
        "id": "6FbihRUQFe1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Add, Concatenate\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "\n",
        "input_layer = Input(shape=(X_train.shape[1],))\n",
        "\n",
        "hidden_layer_1 = Dense(32,activation='relu')(input_layer)\n",
        "\n",
        "hidden_layer_2 = Dense(16,activation='relu')(input_layer)\n",
        "\n",
        "hidden_layer_3 = Dense(16,activation='relu')(hidden_layer_1)\n",
        "\n",
        "add_layer = Concatenate()([hidden_layer_3, hidden_layer_2])\n",
        "\n",
        "output_layer = Dense(1,activation='sigmoid')(add_layer)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)"
      ],
      "metadata": {
        "id": "-ODZq31xlBOl"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=[tf.keras.metrics.Precision(),tf.keras.metrics.Recall()],\n",
        "    )\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "0nCxJiS-F12K",
        "outputId": "510a6c21-7d02-4189-f260-9009b99a54aa"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │        \u001b[38;5;34m576\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m528\u001b[0m │ dense_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m288\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ dense_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,425\u001b[0m (5.57 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,425</span> (5.57 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,425\u001b[0m (5.57 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,425</span> (5.57 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_binary, y_train_binary,\n",
        "                    batch_size = 16,\n",
        "                    epochs = 150,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[early_stopping]\n",
        "                    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpvklKYQGi2Z",
        "outputId": "584c161d-49bf-4c51-fe03-8a948c2e9cd5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.4099 - precision_3: 0.4126 - recall_3: 0.2000 - val_loss: 0.1647 - val_precision_3: 0.8043 - val_recall_3: 0.6948\n",
            "Epoch 2/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.1490 - precision_3: 0.8528 - recall_3: 0.7113 - val_loss: 0.1424 - val_precision_3: 0.8071 - val_recall_3: 0.7465\n",
            "Epoch 3/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1304 - precision_3: 0.8293 - recall_3: 0.7762 - val_loss: 0.1372 - val_precision_3: 0.7917 - val_recall_3: 0.8028\n",
            "Epoch 4/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.1191 - precision_3: 0.8312 - recall_3: 0.7853 - val_loss: 0.1315 - val_precision_3: 0.8168 - val_recall_3: 0.7746\n",
            "Epoch 5/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1245 - precision_3: 0.8393 - recall_3: 0.7842 - val_loss: 0.1307 - val_precision_3: 0.7991 - val_recall_3: 0.8028\n",
            "Epoch 6/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1193 - precision_3: 0.8364 - recall_3: 0.7797 - val_loss: 0.1270 - val_precision_3: 0.8274 - val_recall_3: 0.7653\n",
            "Epoch 7/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1166 - precision_3: 0.8616 - recall_3: 0.7826 - val_loss: 0.1306 - val_precision_3: 0.7660 - val_recall_3: 0.8451\n",
            "Epoch 8/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.1220 - precision_3: 0.8247 - recall_3: 0.7813 - val_loss: 0.1238 - val_precision_3: 0.8497 - val_recall_3: 0.7700\n",
            "Epoch 9/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.1107 - precision_3: 0.8582 - recall_3: 0.8162 - val_loss: 0.1230 - val_precision_3: 0.8204 - val_recall_3: 0.7934\n",
            "Epoch 10/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1011 - precision_3: 0.8493 - recall_3: 0.8231 - val_loss: 0.1245 - val_precision_3: 0.8495 - val_recall_3: 0.7418\n",
            "Epoch 11/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.1112 - precision_3: 0.8592 - recall_3: 0.7943 - val_loss: 0.1258 - val_precision_3: 0.7773 - val_recall_3: 0.8685\n",
            "Epoch 12/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1108 - precision_3: 0.8484 - recall_3: 0.7934 - val_loss: 0.1289 - val_precision_3: 0.7553 - val_recall_3: 0.8404\n",
            "Epoch 13/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.1130 - precision_3: 0.8411 - recall_3: 0.8126 - val_loss: 0.1205 - val_precision_3: 0.8009 - val_recall_3: 0.8498\n",
            "Epoch 14/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1005 - precision_3: 0.8624 - recall_3: 0.8222 - val_loss: 0.1186 - val_precision_3: 0.8108 - val_recall_3: 0.8451\n",
            "Epoch 15/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1015 - precision_3: 0.8616 - recall_3: 0.8194 - val_loss: 0.1202 - val_precision_3: 0.7982 - val_recall_3: 0.8357\n",
            "Epoch 16/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1015 - precision_3: 0.8583 - recall_3: 0.8195 - val_loss: 0.1158 - val_precision_3: 0.8165 - val_recall_3: 0.8357\n",
            "Epoch 17/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1090 - precision_3: 0.8394 - recall_3: 0.8189 - val_loss: 0.1276 - val_precision_3: 0.9091 - val_recall_3: 0.7042\n",
            "Epoch 19/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0999 - precision_3: 0.8670 - recall_3: 0.8102 - val_loss: 0.1166 - val_precision_3: 0.7931 - val_recall_3: 0.8638\n",
            "Epoch 20/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1115 - precision_3: 0.8516 - recall_3: 0.8187 - val_loss: 0.1157 - val_precision_3: 0.8333 - val_recall_3: 0.7981\n",
            "Epoch 21/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.1033 - precision_3: 0.8508 - recall_3: 0.8174 - val_loss: 0.1184 - val_precision_3: 0.7830 - val_recall_3: 0.8638\n",
            "Epoch 22/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1129 - precision_3: 0.8425 - recall_3: 0.8114 - val_loss: 0.1199 - val_precision_3: 0.7815 - val_recall_3: 0.8732\n",
            "Epoch 23/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0970 - precision_3: 0.8497 - recall_3: 0.8191 - val_loss: 0.1201 - val_precision_3: 0.7750 - val_recall_3: 0.8732\n",
            "Epoch 24/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1036 - precision_3: 0.8414 - recall_3: 0.8095 - val_loss: 0.1421 - val_precision_3: 0.6942 - val_recall_3: 0.9061\n",
            "Epoch 25/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1010 - precision_3: 0.8484 - recall_3: 0.8191 - val_loss: 0.1166 - val_precision_3: 0.8670 - val_recall_3: 0.7653\n",
            "Epoch 26/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1057 - precision_3: 0.8650 - recall_3: 0.8200 - val_loss: 0.1126 - val_precision_3: 0.8265 - val_recall_3: 0.8498\n",
            "Epoch 27/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1129 - precision_3: 0.8341 - recall_3: 0.8018 - val_loss: 0.1131 - val_precision_3: 0.8750 - val_recall_3: 0.7887\n",
            "Epoch 28/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0861 - precision_3: 0.8787 - recall_3: 0.8363 - val_loss: 0.1117 - val_precision_3: 0.8364 - val_recall_3: 0.8404\n",
            "Epoch 29/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.1077 - precision_3: 0.8673 - recall_3: 0.8097 - val_loss: 0.1111 - val_precision_3: 0.8206 - val_recall_3: 0.8592\n",
            "Epoch 30/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1058 - precision_3: 0.8630 - recall_3: 0.8083 - val_loss: 0.1107 - val_precision_3: 0.8117 - val_recall_3: 0.8498\n",
            "Epoch 31/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0906 - precision_3: 0.8629 - recall_3: 0.8516 - val_loss: 0.1114 - val_precision_3: 0.7982 - val_recall_3: 0.8545\n",
            "Epoch 32/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1001 - precision_3: 0.8580 - recall_3: 0.8222 - val_loss: 0.1278 - val_precision_3: 0.7364 - val_recall_3: 0.8920\n",
            "Epoch 33/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0929 - precision_3: 0.8768 - recall_3: 0.8312 - val_loss: 0.1106 - val_precision_3: 0.8429 - val_recall_3: 0.8310\n",
            "Epoch 34/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0932 - precision_3: 0.8854 - recall_3: 0.8330 - val_loss: 0.1087 - val_precision_3: 0.8326 - val_recall_3: 0.8404\n",
            "Epoch 35/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0985 - precision_3: 0.8796 - recall_3: 0.8337 - val_loss: 0.1104 - val_precision_3: 0.8325 - val_recall_3: 0.8169\n",
            "Epoch 36/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.1001 - precision_3: 0.8608 - recall_3: 0.8084 - val_loss: 0.1158 - val_precision_3: 0.7792 - val_recall_3: 0.8779\n",
            "Epoch 37/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1040 - precision_3: 0.8529 - recall_3: 0.8130 - val_loss: 0.1152 - val_precision_3: 0.8639 - val_recall_3: 0.7746\n",
            "Epoch 38/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1005 - precision_3: 0.8925 - recall_3: 0.8337 - val_loss: 0.1081 - val_precision_3: 0.8295 - val_recall_3: 0.8451\n",
            "Epoch 39/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0988 - precision_3: 0.8321 - recall_3: 0.8214 - val_loss: 0.1084 - val_precision_3: 0.8382 - val_recall_3: 0.8028\n",
            "Epoch 40/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0874 - precision_3: 0.8740 - recall_3: 0.8444 - val_loss: 0.1089 - val_precision_3: 0.8495 - val_recall_3: 0.8216\n",
            "Epoch 41/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0967 - precision_3: 0.8726 - recall_3: 0.8398 - val_loss: 0.1094 - val_precision_3: 0.8357 - val_recall_3: 0.8122\n",
            "Epoch 42/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0991 - precision_3: 0.8615 - recall_3: 0.8368 - val_loss: 0.1092 - val_precision_3: 0.8161 - val_recall_3: 0.8545\n",
            "Epoch 43/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0899 - precision_3: 0.8557 - recall_3: 0.8460 - val_loss: 0.1066 - val_precision_3: 0.8371 - val_recall_3: 0.8685\n",
            "Epoch 44/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0938 - precision_3: 0.8627 - recall_3: 0.8297 - val_loss: 0.1134 - val_precision_3: 0.7932 - val_recall_3: 0.8826\n",
            "Epoch 45/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0927 - precision_3: 0.8769 - recall_3: 0.8261 - val_loss: 0.1058 - val_precision_3: 0.8416 - val_recall_3: 0.8732\n",
            "Epoch 46/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1005 - precision_3: 0.8638 - recall_3: 0.8377 - val_loss: 0.1109 - val_precision_3: 0.8913 - val_recall_3: 0.7700\n",
            "Epoch 47/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0892 - precision_3: 0.8803 - recall_3: 0.8416 - val_loss: 0.1071 - val_precision_3: 0.8341 - val_recall_3: 0.8732\n",
            "Epoch 48/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0939 - precision_3: 0.8552 - recall_3: 0.8344 - val_loss: 0.1039 - val_precision_3: 0.8545 - val_recall_3: 0.8545\n",
            "Epoch 49/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0904 - precision_3: 0.8727 - recall_3: 0.8393 - val_loss: 0.1047 - val_precision_3: 0.8486 - val_recall_3: 0.8685\n",
            "Epoch 50/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0899 - precision_3: 0.8717 - recall_3: 0.8392 - val_loss: 0.1091 - val_precision_3: 0.7983 - val_recall_3: 0.8920\n",
            "Epoch 51/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0919 - precision_3: 0.8811 - recall_3: 0.8441 - val_loss: 0.1076 - val_precision_3: 0.8026 - val_recall_3: 0.8779\n",
            "Epoch 52/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0873 - precision_3: 0.8705 - recall_3: 0.8404 - val_loss: 0.1087 - val_precision_3: 0.8034 - val_recall_3: 0.8826\n",
            "Epoch 53/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0943 - precision_3: 0.8426 - recall_3: 0.8357 - val_loss: 0.1145 - val_precision_3: 0.7714 - val_recall_3: 0.8873\n",
            "Epoch 54/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0955 - precision_3: 0.8498 - recall_3: 0.8375 - val_loss: 0.1074 - val_precision_3: 0.8426 - val_recall_3: 0.8545\n",
            "Epoch 55/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0982 - precision_3: 0.8761 - recall_3: 0.8347 - val_loss: 0.1099 - val_precision_3: 0.7908 - val_recall_3: 0.8873\n",
            "Epoch 56/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0902 - precision_3: 0.8814 - recall_3: 0.8683 - val_loss: 0.1052 - val_precision_3: 0.8906 - val_recall_3: 0.8028\n",
            "Epoch 57/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0888 - precision_3: 0.8724 - recall_3: 0.8407 - val_loss: 0.1111 - val_precision_3: 0.8069 - val_recall_3: 0.8826\n",
            "Epoch 58/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0948 - precision_3: 0.8693 - recall_3: 0.8184 - val_loss: 0.1144 - val_precision_3: 0.9205 - val_recall_3: 0.7606\n",
            "Epoch 59/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0978 - precision_3: 0.8674 - recall_3: 0.8141 - val_loss: 0.1031 - val_precision_3: 0.8737 - val_recall_3: 0.8122\n",
            "Epoch 60/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0949 - precision_3: 0.8737 - recall_3: 0.8242 - val_loss: 0.1049 - val_precision_3: 0.8371 - val_recall_3: 0.8685\n",
            "Epoch 61/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0873 - precision_3: 0.8584 - recall_3: 0.8463 - val_loss: 0.1063 - val_precision_3: 0.8069 - val_recall_3: 0.8826\n",
            "Epoch 62/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0837 - precision_3: 0.9062 - recall_3: 0.8678 - val_loss: 0.1057 - val_precision_3: 0.8800 - val_recall_3: 0.8263\n",
            "Epoch 63/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0926 - precision_3: 0.8616 - recall_3: 0.8298 - val_loss: 0.1155 - val_precision_3: 0.7590 - val_recall_3: 0.8873\n",
            "Epoch 64/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0868 - precision_3: 0.8727 - recall_3: 0.8527 - val_loss: 0.1038 - val_precision_3: 0.8713 - val_recall_3: 0.8263\n",
            "Epoch 65/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0876 - precision_3: 0.8849 - recall_3: 0.8317 - val_loss: 0.1051 - val_precision_3: 0.8794 - val_recall_3: 0.8216\n",
            "Epoch 66/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0907 - precision_3: 0.8760 - recall_3: 0.8319 - val_loss: 0.1142 - val_precision_3: 0.7778 - val_recall_3: 0.8873\n",
            "Epoch 67/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0891 - precision_3: 0.8638 - recall_3: 0.8382 - val_loss: 0.1041 - val_precision_3: 0.8634 - val_recall_3: 0.8310\n",
            "Epoch 68/150\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0916 - precision_3: 0.8668 - recall_3: 0.8355 - val_loss: 0.1122 - val_precision_3: 0.7683 - val_recall_3: 0.8873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test_binary)\n",
        "print('Macro F1-score is %.2f' %f1_score(y_test_binary, predictions>0.4, average='macro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teBIU0ljHMHw",
        "outputId": "bfc78658-6c7a-47a4-978c-6e3c4ea9fb29"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Macro F1-score is 0.91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Add, Concatenate, Dense, Input\n",
        "from keras.models import Model\n",
        "\n",
        "# Input layer\n",
        "input_layer = Input(shape=(X_train.shape[1],))\n",
        "\n",
        "# First branch\n",
        "hidden_layer_1 = Dense(32, activation='relu')(input_layer)\n",
        "hidden_layer_3 = Dense(16, activation='relu')(hidden_layer_1)\n",
        "\n",
        "# Second branch directly from input\n",
        "hidden_layer_2 = Dense(16, activation='relu')(input_layer)\n",
        "\n",
        "# Merge branches using Concatenate\n",
        "merged = Concatenate()([hidden_layer_3, hidden_layer_2])\n",
        "\n",
        "# Output layer for regression (no activation)\n",
        "output_layer = Dense(1)(merged)\n",
        "\n",
        "# Define model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile for regression\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Summary (optional)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "yl-2JjH6IFlu",
        "outputId": "eb434397-4089-4688-f370-4a16e38b828d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_12\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_12\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │        \u001b[38;5;34m576\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m528\u001b[0m │ dense_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m288\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ dense_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,425\u001b[0m (5.57 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,425</span> (5.57 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,425\u001b[0m (5.57 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,425</span> (5.57 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2 , callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_3df_ETIJwm",
        "outputId": "f332f172-31e3-40a7-bb18-2222ffc27ea9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 1226157.8750 - mae: 1031.2161 - val_loss: 1109532.0000 - val_mae: 974.2645\n",
            "Epoch 2/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 994183.6250 - mae: 910.0832 - val_loss: 473388.5625 - val_mae: 588.7839\n",
            "Epoch 3/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 331203.5938 - mae: 464.6508 - val_loss: 99785.0703 - val_mae: 249.0997\n",
            "Epoch 4/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 93594.6406 - mae: 247.9633 - val_loss: 86198.9141 - val_mae: 237.3623\n",
            "Epoch 5/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 85406.6719 - mae: 236.2311 - val_loss: 79064.7891 - val_mae: 227.6031\n",
            "Epoch 6/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 77027.7891 - mae: 226.2620 - val_loss: 71547.9531 - val_mae: 216.1957\n",
            "Epoch 7/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 69633.1719 - mae: 214.5081 - val_loss: 64293.7070 - val_mae: 205.0811\n",
            "Epoch 8/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 63793.7305 - mae: 203.5060 - val_loss: 56630.8242 - val_mae: 191.3885\n",
            "Epoch 9/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 55816.3438 - mae: 191.3327 - val_loss: 48294.8203 - val_mae: 175.4063\n",
            "Epoch 10/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 46280.8594 - mae: 172.9243 - val_loss: 40800.7266 - val_mae: 159.6863\n",
            "Epoch 11/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 38736.1875 - mae: 156.3018 - val_loss: 34333.9336 - val_mae: 145.1241\n",
            "Epoch 12/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 33541.4336 - mae: 144.1496 - val_loss: 29936.7793 - val_mae: 135.6257\n",
            "Epoch 13/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 29632.5586 - mae: 136.5726 - val_loss: 27308.8730 - val_mae: 129.4643\n",
            "Epoch 14/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 26915.5547 - mae: 127.2203 - val_loss: 25709.1328 - val_mae: 124.1389\n",
            "Epoch 15/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 25086.2363 - mae: 122.6089 - val_loss: 24801.0684 - val_mae: 121.7515\n",
            "Epoch 16/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 23762.6406 - mae: 119.2371 - val_loss: 24181.8594 - val_mae: 120.3544\n",
            "Epoch 17/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 24653.1582 - mae: 120.0824 - val_loss: 23743.5566 - val_mae: 119.4016\n",
            "Epoch 18/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 24340.5547 - mae: 118.2843 - val_loss: 23305.9082 - val_mae: 118.1290\n",
            "Epoch 19/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 22945.1270 - mae: 115.6678 - val_loss: 23110.8965 - val_mae: 118.0013\n",
            "Epoch 20/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 23290.1934 - mae: 115.9331 - val_loss: 22625.3086 - val_mae: 115.9122\n",
            "Epoch 21/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 23245.8438 - mae: 115.9005 - val_loss: 22327.4980 - val_mae: 115.3351\n",
            "Epoch 22/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 22798.2695 - mae: 114.5173 - val_loss: 22117.6504 - val_mae: 115.3547\n",
            "Epoch 23/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 22142.4648 - mae: 114.0957 - val_loss: 21820.6523 - val_mae: 113.7630\n",
            "Epoch 24/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 21790.3848 - mae: 112.0580 - val_loss: 21569.3223 - val_mae: 113.1840\n",
            "Epoch 25/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 21240.4551 - mae: 111.6770 - val_loss: 21358.1895 - val_mae: 112.9099\n",
            "Epoch 26/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 20575.8281 - mae: 109.8672 - val_loss: 21150.1738 - val_mae: 112.3380\n",
            "Epoch 27/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 20612.7363 - mae: 110.2908 - val_loss: 20966.2969 - val_mae: 111.8343\n",
            "Epoch 28/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 19805.8457 - mae: 107.9582 - val_loss: 20784.8867 - val_mae: 111.4277\n",
            "Epoch 29/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 20273.0020 - mae: 109.3520 - val_loss: 20584.0312 - val_mae: 110.7144\n",
            "Epoch 30/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 19997.1523 - mae: 107.1481 - val_loss: 20449.1309 - val_mae: 110.2556\n",
            "Epoch 31/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 20301.1738 - mae: 108.5480 - val_loss: 20304.0918 - val_mae: 110.5600\n",
            "Epoch 32/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 20343.4316 - mae: 108.5658 - val_loss: 20085.8906 - val_mae: 109.7329\n",
            "Epoch 33/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 20019.4258 - mae: 106.6358 - val_loss: 19919.9355 - val_mae: 109.2319\n",
            "Epoch 34/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 19268.4805 - mae: 107.0301 - val_loss: 19761.1270 - val_mae: 108.8760\n",
            "Epoch 35/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 19479.3457 - mae: 107.4454 - val_loss: 19656.5273 - val_mae: 108.2081\n",
            "Epoch 36/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 20033.9395 - mae: 107.3057 - val_loss: 19473.6172 - val_mae: 107.4988\n",
            "Epoch 37/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 20127.4863 - mae: 107.9134 - val_loss: 19412.2480 - val_mae: 106.8014\n",
            "Epoch 38/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 18336.8652 - mae: 103.1711 - val_loss: 19175.1934 - val_mae: 107.3318\n",
            "Epoch 39/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 18569.6582 - mae: 105.3999 - val_loss: 19078.1680 - val_mae: 107.3444\n",
            "Epoch 40/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 18381.1016 - mae: 102.9007 - val_loss: 18891.9297 - val_mae: 106.2842\n",
            "Epoch 41/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 18506.6387 - mae: 103.1814 - val_loss: 18752.4570 - val_mae: 105.7960\n",
            "Epoch 42/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 18240.1836 - mae: 101.9461 - val_loss: 18783.3340 - val_mae: 106.9356\n",
            "Epoch 43/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 17663.8105 - mae: 102.0228 - val_loss: 18490.5312 - val_mae: 104.8985\n",
            "Epoch 44/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 17546.0879 - mae: 100.7797 - val_loss: 18385.8184 - val_mae: 104.3439\n",
            "Epoch 45/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 18056.2559 - mae: 101.7472 - val_loss: 18255.9590 - val_mae: 104.0477\n",
            "Epoch 46/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 18176.2734 - mae: 102.4713 - val_loss: 18150.0410 - val_mae: 104.0896\n",
            "Epoch 47/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 17814.8223 - mae: 101.1473 - val_loss: 18094.8145 - val_mae: 103.4307\n",
            "Epoch 48/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 17594.3574 - mae: 101.0908 - val_loss: 17997.5410 - val_mae: 103.8963\n",
            "Epoch 49/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 17263.0098 - mae: 100.8922 - val_loss: 17897.0078 - val_mae: 102.8884\n",
            "Epoch 50/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 17055.3008 - mae: 99.2902 - val_loss: 17849.0020 - val_mae: 103.4566\n",
            "Epoch 51/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 17315.8965 - mae: 100.1241 - val_loss: 17749.6641 - val_mae: 102.9401\n",
            "Epoch 52/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 17624.4492 - mae: 100.1918 - val_loss: 17672.1035 - val_mae: 102.5974\n",
            "Epoch 53/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16344.1182 - mae: 97.6624 - val_loss: 17611.5898 - val_mae: 102.3926\n",
            "Epoch 54/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16562.9082 - mae: 99.1537 - val_loss: 17541.1406 - val_mae: 102.1820\n",
            "Epoch 55/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16900.9902 - mae: 99.9532 - val_loss: 17496.5215 - val_mae: 101.5871\n",
            "Epoch 56/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 17416.4219 - mae: 99.9070 - val_loss: 17401.0195 - val_mae: 101.8857\n",
            "Epoch 57/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16384.8535 - mae: 96.7986 - val_loss: 17334.7598 - val_mae: 101.6137\n",
            "Epoch 58/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 18030.0430 - mae: 102.3673 - val_loss: 17268.0977 - val_mae: 101.2529\n",
            "Epoch 59/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 17001.5664 - mae: 99.1887 - val_loss: 17332.5918 - val_mae: 102.2511\n",
            "Epoch 60/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16409.9219 - mae: 98.4481 - val_loss: 17213.0312 - val_mae: 101.5369\n",
            "Epoch 61/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16737.0312 - mae: 98.8809 - val_loss: 17115.9863 - val_mae: 100.9127\n",
            "Epoch 62/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16420.0918 - mae: 97.9869 - val_loss: 17064.5684 - val_mae: 100.8228\n",
            "Epoch 63/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16401.2715 - mae: 97.8225 - val_loss: 17051.4121 - val_mae: 100.0396\n",
            "Epoch 64/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15896.0098 - mae: 96.5319 - val_loss: 17041.9336 - val_mae: 101.2874\n",
            "Epoch 65/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15928.1055 - mae: 97.5907 - val_loss: 16965.0078 - val_mae: 100.3207\n",
            "Epoch 66/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 17351.8691 - mae: 98.8409 - val_loss: 16894.9180 - val_mae: 100.3782\n",
            "Epoch 67/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 16657.5488 - mae: 99.1413 - val_loss: 16832.0488 - val_mae: 100.1219\n",
            "Epoch 68/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 15768.2627 - mae: 95.3184 - val_loss: 16904.6406 - val_mae: 99.2607\n",
            "Epoch 69/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 17259.1484 - mae: 98.5969 - val_loss: 16745.7891 - val_mae: 99.8856\n",
            "Epoch 70/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16724.2754 - mae: 98.1462 - val_loss: 16714.0938 - val_mae: 99.7543\n",
            "Epoch 71/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16128.1357 - mae: 97.8721 - val_loss: 16717.5879 - val_mae: 99.1989\n",
            "Epoch 72/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16540.5469 - mae: 98.2286 - val_loss: 16651.8535 - val_mae: 99.5236\n",
            "Epoch 73/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16210.2217 - mae: 97.3649 - val_loss: 16612.0996 - val_mae: 99.3408\n",
            "Epoch 74/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15461.4229 - mae: 94.8178 - val_loss: 16597.7207 - val_mae: 98.9638\n",
            "Epoch 75/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16782.0547 - mae: 96.5775 - val_loss: 16583.4609 - val_mae: 99.6985\n",
            "Epoch 76/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 17071.7520 - mae: 98.3617 - val_loss: 16600.0957 - val_mae: 98.4648\n",
            "Epoch 77/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16070.3711 - mae: 97.5532 - val_loss: 16533.8320 - val_mae: 99.6898\n",
            "Epoch 78/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16214.5117 - mae: 96.9622 - val_loss: 16497.6875 - val_mae: 99.5225\n",
            "Epoch 79/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16051.8604 - mae: 96.7743 - val_loss: 16611.2793 - val_mae: 98.3526\n",
            "Epoch 80/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15425.1270 - mae: 94.9809 - val_loss: 16419.9766 - val_mae: 99.0656\n",
            "Epoch 81/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15932.4785 - mae: 96.3766 - val_loss: 16683.2266 - val_mae: 100.8580\n",
            "Epoch 82/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 15507.1836 - mae: 96.3613 - val_loss: 16405.0215 - val_mae: 99.2471\n",
            "Epoch 83/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 15617.9082 - mae: 96.0560 - val_loss: 16371.8154 - val_mae: 97.7639\n",
            "Epoch 84/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 15736.3604 - mae: 95.7374 - val_loss: 16341.5908 - val_mae: 97.7212\n",
            "Epoch 85/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15904.2646 - mae: 96.5480 - val_loss: 16234.3486 - val_mae: 97.7856\n",
            "Epoch 86/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15074.3994 - mae: 94.2717 - val_loss: 16238.5586 - val_mae: 98.5799\n",
            "Epoch 87/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15442.2920 - mae: 95.1056 - val_loss: 16193.0781 - val_mae: 98.0087\n",
            "Epoch 88/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16070.7422 - mae: 97.1798 - val_loss: 16130.7773 - val_mae: 97.7125\n",
            "Epoch 89/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15554.7793 - mae: 95.4977 - val_loss: 16140.8154 - val_mae: 97.6531\n",
            "Epoch 90/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15741.0781 - mae: 95.0968 - val_loss: 16089.5547 - val_mae: 97.1813\n",
            "Epoch 91/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15702.3467 - mae: 96.5442 - val_loss: 16142.1748 - val_mae: 96.8753\n",
            "Epoch 92/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16073.9229 - mae: 95.9122 - val_loss: 16013.7412 - val_mae: 97.2225\n",
            "Epoch 93/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15332.1699 - mae: 95.0157 - val_loss: 16047.0791 - val_mae: 98.1258\n",
            "Epoch 94/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15192.7793 - mae: 93.9649 - val_loss: 15978.1318 - val_mae: 97.1411\n",
            "Epoch 95/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15692.3691 - mae: 95.4205 - val_loss: 15949.2041 - val_mae: 96.8448\n",
            "Epoch 96/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16177.8086 - mae: 95.2183 - val_loss: 15955.6768 - val_mae: 96.7011\n",
            "Epoch 97/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15185.5039 - mae: 94.1877 - val_loss: 15866.7920 - val_mae: 96.9280\n",
            "Epoch 98/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 15653.4590 - mae: 95.3439 - val_loss: 15990.5674 - val_mae: 96.3843\n",
            "Epoch 99/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 15212.5723 - mae: 94.7798 - val_loss: 16168.5449 - val_mae: 99.2710\n",
            "Epoch 100/100\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 15554.6660 - mae: 95.1851 - val_loss: 15817.9590 - val_mae: 97.0366\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f550245c450>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(X_test)\n",
        "print(r2_score(y_test, prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmS9_aJkIvdd",
        "outputId": "597080b4-4971-49be-b7d5-16c080ac546a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "0.8955653405710826\n"
          ]
        }
      ]
    }
  ]
}